{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S62g2sVMRnBD"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWExR6D6UXwn"
      },
      "outputs": [],
      "source": [
        "!sudo apt install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2Jce9iyT1JF"
      },
      "outputs": [],
      "source": [
        "pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAdxgiWFYeeT"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q replicate"
      ],
      "metadata": {
        "id": "Q8mdxtaGHieU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG3rcav6DGIC",
        "outputId": "eee9ca1f-932a-4e71-fc76-8892d3e1026f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from pdf2image import convert_from_bytes\n",
        "import pytesseract\n",
        "import re\n",
        "import replicate\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_GHG89WAPgiMQEsm3r5UzIzxKFkUpPFi0fLzSe\"\n",
        "\n",
        "# Function to convert pdf bytes to images\n",
        "def pdf_to_img(pdf_bytes):\n",
        "    images = convert_from_bytes(pdf_bytes)\n",
        "    for i, image in enumerate(images):\n",
        "        image.save(f\"page_{i+1}.jpg\", \"JPEG\")\n",
        "\n",
        "# Function to extract text from images using Tesseract OCR\n",
        "def extract_text_from_images():\n",
        "    text = \"\"\n",
        "    for i in range(2):\n",
        "        filename = f\"page_{i+1}.jpg\"\n",
        "        text += pytesseract.image_to_string(filename)\n",
        "    return text\n",
        "\n",
        "# Function to extract data from text\n",
        "def extract_data_from_text(text):\n",
        "    categoriser_data = {}\n",
        "\n",
        "    # Name Extraction\n",
        "    name = text.split(\"\\n\")[0]\n",
        "    categoriser_data['name'] = name\n",
        "\n",
        "    # College Name Extraction\n",
        "    pattern = r\"(?i)\\b(SRM\\s+(?:University|Institute)\\s+of\\s+Science\\s+and\\s+Technology)\"\n",
        "    college = re.search(pattern, text)\n",
        "\n",
        "    if college:\n",
        "        university = college.group(0)\n",
        "        categoriser_data['college'] = university\n",
        "    else:\n",
        "        categoriser_data['college'] = \"University name not found\"\n",
        "\n",
        "    # GPA Extraction\n",
        "    start_index = text.find(\"GPA:\")\n",
        "    if start_index != -1:\n",
        "        end_index = text.find(\"\\n\", start_index)\n",
        "        gpa = text[start_index + 4:end_index].strip()  # 4 to skip \"GPA: \"\n",
        "        categoriser_data['cgpa'] = gpa\n",
        "    else:\n",
        "        categoriser_data['cgpa'] = \"GPA not found\"\n",
        "\n",
        "    # Internships Section\n",
        "    start_index = text.find(\"LEADERSHIP & EXPERIENCE\")\n",
        "    if start_index == -1:\n",
        "        raise ValueError(\"Leadership & Experience section not found\")\n",
        "\n",
        "    end_index = text.find(\"PROJECTS\", start_index)\n",
        "    if end_index == -1:\n",
        "        raise ValueError(\"Projects section not found\")\n",
        "\n",
        "    section = text[start_index:end_index].strip()\n",
        "    categoriser_data['internships'] = section\n",
        "\n",
        "    # Projects Section\n",
        "    project_start_index = text.find(\"PROJECTS\")\n",
        "    if project_start_index == -1:\n",
        "        raise ValueError(\"projects section not found\")\n",
        "\n",
        "    project_end_index = text.find(\"TECH SOCIETIES\", project_start_index)\n",
        "    if project_end_index == -1:\n",
        "        raise ValueError(\"tech societies section not found\")\n",
        "\n",
        "    projects_section = text[project_start_index:project_end_index].strip()\n",
        "    categoriser_data['projects'] = projects_section\n",
        "\n",
        "    return categoriser_data\n",
        "\n",
        "# Load the model\n",
        "with open('model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "\n",
        "show_recommendation = False\n",
        "\n",
        "def start_page():\n",
        "\n",
        "    # Initialize variables\n",
        "    category_person = None\n",
        "    question_arr = None\n",
        "\n",
        "\n",
        "    # Display file uploader for document file\n",
        "    document_file = st.file_uploader(\"Upload document file\", type=['pdf'])\n",
        "\n",
        "    if document_file:\n",
        "        # Convert pdf bytes to images\n",
        "        pdf_to_img(document_file.getvalue())\n",
        "        st.write(\"Document file processed and converted to images\")\n",
        "\n",
        "        # Extract text from images\n",
        "        text = extract_text_from_images()\n",
        "\n",
        "        # Extract data from text\n",
        "        categoriser_data = extract_data_from_text(text)\n",
        "\n",
        "        # Display the extracted data\n",
        "        st.write(\"Extracted data:\", categoriser_data)\n",
        "\n",
        "        # Create a placeholder for the user inputs\n",
        "        user_inputs = {}\n",
        "\n",
        "        # Create a dictionary to store presence indicators\n",
        "        presence_indicators = {\n",
        "            'internships_done': 0,\n",
        "            'projects_done': 0,\n",
        "            'research_done': 0,\n",
        "            'social_groups_joined': 0,\n",
        "            'volunteering_exp': 0,\n",
        "            'pof_done': 0\n",
        "        }\n",
        "\n",
        "        # Display the form for each variable\n",
        "        st.title(\"Variable Input Form\")\n",
        "        input_variables = ['name', 'age', 'college', 'year_of_study', 'cgpa', 'preferred_univ', 'internships', 'projects',\n",
        "                           'research_papers', 'social_groups', 'volunteering', 'position_of_resp']\n",
        "        for variable in input_variables:\n",
        "            # Check if the variable is present in the categoriser_data dictionary\n",
        "            if variable in categoriser_data:\n",
        "                default_value = categoriser_data[variable]\n",
        "            else:\n",
        "                default_value = \"\"\n",
        "\n",
        "            # Create input field for the variable\n",
        "            user_input = st.text_input(f\"Enter value for {variable}:\", value=default_value)\n",
        "\n",
        "            # If input is empty, mark it as None\n",
        "            if not user_input:\n",
        "                user_inputs[variable] = \"\"\n",
        "            else:\n",
        "                user_inputs[variable] = user_input\n",
        "\n",
        "            # Update presence indicators\n",
        "            if variable == 'internships' and user_input != \"\":\n",
        "                presence_indicators['internships_done'] = 1\n",
        "            if variable == 'projects' and user_input != \"\":\n",
        "                presence_indicators['projects_done'] = 1\n",
        "            if variable == 'research_papers' and user_input != \"\":\n",
        "                presence_indicators['research_done'] = 1\n",
        "            if variable == 'social_groups' and user_input != \"\":\n",
        "                presence_indicators['social_groups_joined'] = 1\n",
        "            if variable == 'volunteering' and user_input != \"\":\n",
        "                presence_indicators['volunteering_exp'] = 1\n",
        "            if variable == 'position_of_resp' and user_input != \"\":\n",
        "                presence_indicators['pof_done'] = 1\n",
        "\n",
        "        # Mapping presence indicators to parameters in the data\n",
        "        indicator_to_param = {\n",
        "            \"internships_done\": \"internships\",\n",
        "            \"projects_done\": \"projects\",\n",
        "            \"research_done\": \"research_papers\",\n",
        "            \"social_groups_joined\": \"social_groups\",\n",
        "            \"volunteering_exp\": \"volunteering\",\n",
        "            \"pof_done\": \"position_of_resp\"\n",
        "        }\n",
        "\n",
        "        # Define missing and present parameters based on presence indicators\n",
        "        missing_parameters = [key for key, value in presence_indicators.items() if value == 0]\n",
        "        present_parameters = [indicator_to_param[indicator] for indicator, value in presence_indicators.items() if value == 1]\n",
        "\n",
        "        prompts = []\n",
        "\n",
        "        # Generate prompts for each category\n",
        "        for param in missing_parameters:\n",
        "            prompt = f\"My name is {user_inputs['name']}, can you please highlight some things which I should take care, while writing about my {param.replace('_', ' ')}, please be specific and just write everything in points. Also, give responses like you are talking to a real person and be polite while calling names and everything\"\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        for param in present_parameters:\n",
        "            prompt = f\"My name is {user_inputs['name']}, list out the things which I can improve, while telling about my {param.replace('_', ' ')}, please be specific and just write everything in points. Also, give responses like you are talking to a real person and be polite while calling names and everything\"\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        # Generate prompt for university preference\n",
        "        univ_prompt = f\"My name is {user_inputs['name']}, I am currently in my {user_inputs['year_of_study']} at {user_inputs['college']}. I want to go in these {user_inputs['preferred_univ']} universities. Can you list a tailored structure of how to get into these universities, please be specific and just write everything in points. Also, give responses like you are talking to a real person and be polite while calling names and everything\"\n",
        "        prompts.append(univ_prompt)\n",
        "\n",
        "        # Generate prompt for GRE preparation\n",
        "        gre_prompt = f\"My name is {user_inputs['name']}, I am currently in my {user_inputs['year_of_study']}, do you think this is the right time for me to prepare for GRE, and tell me is GRE necessary for {user_inputs['preferred_univ']}. If you think this is the right time to start, how should I prepare for it?, please be specific and just write everything in points. Also, give responses like you are talking to a real person and be polite while calling names and everything\"\n",
        "        prompts.append(gre_prompt)\n",
        "\n",
        "        # Generate prompt for SOP (Statement of Purpose) for desired university\n",
        "        sop_prompt = f\"My name is {user_inputs['name']}, I am applying for admission to {user_inputs['preferred_univ']}. Can you guide me on how to write a compelling Statement of Purpose (SOP) specifically tailored for this university? Please include key points to cover and any specific requirements or tips from your experience. Also, give responses like you are talking to a real person and be polite while calling names and everything.\"\n",
        "        prompts.append(sop_prompt)\n",
        "\n",
        "        # Get the data for present parameters\n",
        "        present_data = {key: user_inputs[key] for key in present_parameters}\n",
        "\n",
        "        # Generate improvement prompt including present data\n",
        "        improvement_prompt = f\"My name is {user_inputs['name']}, I have provided information about my {', '.join(present_parameters)}. Here are the details:\\n\\n\"\n",
        "        for param, value in present_data.items():\n",
        "          improvement_prompt += f\"{param.replace('_', ' ')}: {value}\\n\"\n",
        "        improvement_prompt += \"\\nCan you suggest any improvements or additional details I should include to make my profile more compelling for university applications or job opportunities? Please provide specific advice and suggestions. Also, give responses like you are talking to a real person and be polite while calling names and everything.\"\n",
        "\n",
        "        prompts.append(improvement_prompt)\n",
        "\n",
        "        # Generate prompt for preparing for interviews\n",
        "        interview_prompt = f\"My name is {user_inputs['name']}, I am preparing for interviews for internships or job opportunities. Can you provide tips and strategies for preparing effectively for technical and behavioral interviews? Please include common questions, how to approach technical assessments, and advice for presenting my experience and skills confidently. Also, give responses like you are talking to a real person and be polite while calling names and everything.\"\n",
        "        prompts.append(interview_prompt)\n",
        "\n",
        "        # Generate prompt for improving communication skills\n",
        "        communication_prompt = f\"My name is {user_inputs['name']}, I want to improve my communication skills, both written and verbal, to enhance my professional profile. Can you suggest resources, courses, or activities that can help me develop effective communication skills? Please include practical tips and exercises for improving clarity, coherence, and persuasiveness in communication. Also, give responses like you are talking to a real person and be polite while calling names and everything.\"\n",
        "        prompts.append(communication_prompt)\n",
        "\n",
        "        # Add a submit button\n",
        "        if st.button(\"Submit\"):\n",
        "          # Create DataFrame from presence_indicators dictionary\n",
        "          df = pd.DataFrame([presence_indicators])\n",
        "\n",
        "          show_recommendation = True\n",
        "\n",
        "          # Make prediction using loaded model\n",
        "          category_person = loaded_model.predict(df)[0]\n",
        "          question_arr = prompts\n",
        "\n",
        "          # Store category_person and question_arr in session state\n",
        "          st.session_state['category_person'] = category_person\n",
        "          st.session_state['question_arr'] = question_arr\n",
        "\n",
        "          return None\n",
        "\n",
        "    return None\n",
        "\n",
        "# model=\"meta-llama/Llama-2-7b-chat-hf\"\n",
        "# tokenizer=AutoTokenizer.from_pretrained(model)\n",
        "# pipeline=transformers.pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     torch_dtype=torch.bfloat16,\n",
        "#     trust_remote_code=True,\n",
        "#     device_map=\"auto\",\n",
        "#     min_length=200,\n",
        "#     max_length=1000,\n",
        "#     do_sample=True,\n",
        "#     top_k=10,\n",
        "#     num_return_sequences=1,\n",
        "#     eos_token_id=tokenizer.eos_token_id\n",
        "#     )\n",
        "\n",
        "# llm=HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0.7})\n",
        "\n",
        "\n",
        "# deaken_data = [\"\"\"Deaken University English Language Requirements\n",
        "# English Language Requirements:\n",
        "# TOEFL iBT: Minimum score of 79-93 depending on the program.\n",
        "# IELTS: Minimum overall score of 6.0-7.0 with no band lower than 6.0 depending on the program.\n",
        "# PTE Academic: Minimum score of 58-64 depending on the program.\n",
        "# GRE Requirements:\n",
        "\n",
        "# GRE Score Requirements:\n",
        "# Graduate Programs: Many graduate programs, particularly those in business, education, and humanities, require the GRE.\n",
        "# The minimum score requirement varies depending on the program, but it's typically in the range of 300-330 for the verbal and quantitative sections.\n",
        "# Some programs may also require the writing section with a minimum score of 3.5.\n",
        "\n",
        "# Additional Requirements:\n",
        "\n",
        "# Work experience: Some programs may require relevant work experience.\n",
        "# Portfolio: Creative programs may require a portfolio of your work.\n",
        "# Statement of purpose: A well-written statement of purpose is essential for all applications.\n",
        "\n",
        "# Research requirements:\n",
        "# Instead, the focus is on demonstrating your research potential and suitability for the specific program you're applying to. To achieve this, they require several key documents:\n",
        "# 1. Academic Transcripts: These showcase your academic performance in coursework relevant to your research interests.\n",
        "# 2. Statement of Purpose: This document allows you to express your research interests, motivations, and relevant skills and experiences. It's your chance to highlight your specific contributions to the field and why you're a good fit for the program.\n",
        "# 3. Research Proposal: While not always mandatory, some programs may request a research proposal outlining your proposed research topic, methodology, and expected outcomes. This helps assess your research skills and alignment with the program's focus.\n",
        "# 4. References: Academic referees familiar with your academic achievements and research potential can provide valuable insights to the admissions committee.\n",
        "# 5. Additional documents: Depending on the program, you might need to submit work samples, publications (if any), evidence of research experience, or other relevant materials.\n",
        "\n",
        "# Statement of Purpose:\n",
        "# Template:\n",
        "\n",
        "# Introduction:\n",
        "\n",
        "# Briefly introduce yourself and state your intention to apply to a specific program at Deakin University.\n",
        "# Mention the semester and year you are applying for.\n",
        "# Academic Background and Achievements:\n",
        "\n",
        "# Highlight your relevant academic background, including your degree(s), relevant coursework, and your overall academic performance.\n",
        "# Mention any academic awards, scholarships, or distinctions you have received.\n",
        "# Research Experience and Interests:\n",
        "\n",
        "# If applicable, describe your research experience (e.g., internships, lab work, independent projects).\n",
        "# Clearly articulate your research interests and align them with the specific program you are applying to.\n",
        "# Mention specific faculty members whose research aligns with your interests and how you see yourself contributing to their work.\n",
        "# Motivations and Goals:\n",
        "\n",
        "# Explain your motivations for pursuing this program at Deakin University. What attracts you to the program and the university?\n",
        "# Clearly state your short-term and long-term career goals and how this program will help you achieve them.\n",
        "# Conclusion:\n",
        "\n",
        "# Briefly summarize your key strengths and qualifications.\n",
        "# Reiterate your enthusiasm for the program and express your gratitude for the committee's time and consideration.\n",
        "# Tips:\n",
        "\n",
        "# Be specific and relevant: Tailor your statement to the specific program you are applying to. Highlight skills and experiences directly related to the program's requirements and research focus.\n",
        "# Demonstrate your passion: Show your genuine interest in the program and the field of research. Use specific examples and evidence to support your claims.\n",
        "# Be concise and clear: Aim for a clear and concise statement within the suggested word limit. Use strong verbs and avoid unnecessary jargon.\n",
        "# Proofread carefully: Ensure your statement is free of grammatical errors and typos.\n",
        "# \"\"\"]\n",
        "\n",
        "# vectorstore = FAISS.from_texts(\n",
        "#   deaken_data, embedding=HuggingFaceEmbeddings()\n",
        "# )\n",
        "\n",
        "# # Create a retriever from the vectorstore\n",
        "# retriever = vectorstore.as_retriever()\n",
        "\n",
        "# # Create a new prompt template using the HuggingFace embeddings\n",
        "# template = \"\"\"Answer the question based only on the following context: {context}\n",
        "\n",
        "# Question: {question}\n",
        "# \"\"\"\n",
        "\n",
        "# min_tokens = 256\n",
        "\n",
        "# prompt = ChatPromptTemplate.from_template(template, min_tokens=min_tokens)\n",
        "\n",
        "# chain = (\n",
        "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "#     | prompt\n",
        "#     | llm\n",
        "#     | StrOutputParser()\n",
        "# )\n",
        "\n",
        "# # Create a new FAISS vectorstore using the HuggingFace embeddings\n",
        "# vectorstore = FAISS.from_texts(\n",
        "#   deaken_data, embedding=HuggingFaceEmbeddings()\n",
        "# )\n",
        "\n",
        "# # Create a retriever from the vectorstore\n",
        "# retriever = vectorstore.as_retriever()\n",
        "\n",
        "# # Create a new prompt template using the HuggingFace embeddings\n",
        "# template = \"\"\"Answer the question based only on the following context: {context}\n",
        "\n",
        "# Question: {question}\n",
        "# \"\"\"\n",
        "\n",
        "# prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# chain = (\n",
        "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "#     | prompt\n",
        "#     | llm\n",
        "#     | StrOutputParser()\n",
        "# )\n",
        "\n",
        "# chain.invoke(\"What all things are required to get into Deaken University\")\n",
        "\n",
        "\n",
        "def question_and_answer(question, answer):\n",
        "    \"\"\"Create a question and answer card with a dropdown icon.\n",
        "\n",
        "    Args:\n",
        "        question: The question to be displayed on the card.\n",
        "        answer: The answer to be displayed on the card.\n",
        "    \"\"\"\n",
        "    with st.expander(question):\n",
        "        st.write(answer)\n",
        "\n",
        "\n",
        "def recommendation():\n",
        "  st.title(\"Recommendation\")\n",
        "  st.write(\"## Question and Answer\")\n",
        "\n",
        "  if 'category_person' in st.session_state and 'question_arr' in st.session_state:\n",
        "    category_person = st.session_state['category_person']\n",
        "    question_arr = st.session_state['question_arr']\n",
        "    st.write(\"Category: \", category_person)\n",
        "    st.write(\"Question list: \", question_arr)\n",
        "\n",
        "    # Add your questions and answers here\n",
        "    questions = question_arr  # Assuming question_arr is the list of prompts\n",
        "    answers = []\n",
        "\n",
        "    # Track current question index and initialize to 0\n",
        "    current_question_index = st.session_state.get('current_question_index', 0)\n",
        "\n",
        "    # Display logic with button handling\n",
        "    if current_question_index < len(questions):\n",
        "      question_prompt = questions[current_question_index]\n",
        "\n",
        "      # Generate answer using large language model\n",
        "      output = replicate.run(\n",
        "          \"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\",\n",
        "          input={\"prompt\": question_prompt,\n",
        "                 \"temperature\": 0.75,\n",
        "                 \"max_new_tokens\": 2000,\n",
        "                 \"min_new_tokens\": 256}\n",
        "      )\n",
        "\n",
        "      response_text = \"\".join(item for item in output)\n",
        "      answers.append(response_text)\n",
        "\n",
        "      # Display the question and answer\n",
        "      question_and_answer(question_prompt, response_text)\n",
        "\n",
        "      # Button layout with Prev and Next\n",
        "      col1, col2 = st.columns(2)\n",
        "      if current_question_index > 0:\n",
        "        if col1.button(\"Previous\"):\n",
        "          current_question_index -= 1\n",
        "      if current_question_index < len(questions) - 1:\n",
        "        if col2.button(\"Next\"):\n",
        "          current_question_index += 1\n",
        "\n",
        "      # Update session state with the new index\n",
        "      st.session_state['current_question_index'] = current_question_index\n",
        "\n",
        "  else:\n",
        "        st.write(\"Please fill out the form on the previous page.\")\n",
        "\n",
        "\n",
        "def personal_ques():\n",
        "  st.title(\"Help Page\")\n",
        "\n",
        "  # User input for question\n",
        "  question = st.text_area(\"Ask your question here:\")\n",
        "\n",
        "  # Generate answer using large language model (replace with your specific API call)\n",
        "  if question:\n",
        "    output = replicate.run(\n",
        "        \"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\",\n",
        "        input={\"prompt\": question,\n",
        "               \"temperature\": 0.75,\n",
        "               \"max_new_tokens\": 2000,\n",
        "               \"min_new_tokens\": 256}\n",
        "    )\n",
        "\n",
        "    response_text = \"\".join(item for item in output)\n",
        "    question_and_answer(\"Your Question:\", question)\n",
        "    question_and_answer(\"Answer:\", response_text)\n",
        "\n",
        "  else:\n",
        "    st.write(\"Please enter your question.\")\n",
        "\n",
        "def main():\n",
        "    st.sidebar.title('Navigation')\n",
        "    page = st.sidebar.radio(\"Go to\", ['Data Extraction and Variable Input Form', 'Recommendation', 'Help'])\n",
        "\n",
        "    user_inputs = {}\n",
        "\n",
        "    if page == 'Data Extraction and Variable Input Form':\n",
        "        start_page()\n",
        "    if show_recommendation:\n",
        "        recommendation()\n",
        "    elif page == 'Recommendation':\n",
        "        recommendation()\n",
        "    elif page == 'Help':\n",
        "        personal_ques()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpzcbyUDGli_"
      },
      "outputs": [],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pfw9PZgGrHO"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qv7ihGUoG3hF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}